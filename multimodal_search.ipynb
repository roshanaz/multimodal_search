{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "# !pip install weaviate-client sentence-transformers pillow numpy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import weaviate\n",
    "from weaviate.classes.config import Configure, Property, DataType, Multi2VecField\n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CLIP model\n",
    "clip_model = SentenceTransformer('clip-ViT-B-32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_data(image_path):\n",
    "    \"\"\"Read image as base64 and PIL object, caching to avoid redundant reads\"\"\"\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        raw_data = img_file.read()\n",
    "        base64_data = base64.b64encode(raw_data).decode(\"utf-8\")\n",
    "        pil_img = Image.open(io.BytesIO(raw_data))\n",
    "    return base64_data, pil_img\n",
    "\n",
    "def process_metadata(metadata, max_chars=300):\n",
    "    \"\"\"Process captions from metadata\"\"\"\n",
    "    captions = metadata.get(\"captions\", [])\n",
    "    concatenated = \" \".join(captions)[:max_chars] if captions else \"No captions available\"\n",
    "    return concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flickr_schema_multi2vec(client):\n",
    "    \"\"\"Create schema for multi2vec-clip\"\"\"\n",
    "    if client.collections.exists(\"Flickr30k_multi2vec\"):\n",
    "        print(\"Flickr30k_multi2vec exists, skipping creation\")\n",
    "        return\n",
    "    client.collections.create(\n",
    "        \"Flickr30k_multi2vec\",\n",
    "        properties=[\n",
    "            Property(name=\"image\", data_type=DataType.BLOB),\n",
    "            Property(name=\"image_id\", data_type=DataType.TEXT),\n",
    "            Property(name=\"captions\", data_type=DataType.TEXT),\n",
    "        ],\n",
    "        vectorizer_config=[\n",
    "            Configure.NamedVectors.multi2vec_clip(\n",
    "                name=\"image_vector\",\n",
    "                image_fields=[Multi2VecField(name=\"image\", weight=0.7)],\n",
    "                text_fields=[Multi2VecField(name=\"captions\", weight=0.3)]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    print(\"Created Flickr30k_multi2vec schema\")\n",
    "\n",
    "def create_flickr_schema_manual(client):\n",
    "    \"\"\"Create schema for manual vectorization\"\"\"\n",
    "    if client.collections.exists(\"Flickr30k_manual\"):\n",
    "        print(\"Flickr30k_manual exists, skipping creation\")\n",
    "        return\n",
    "    client.collections.create(\n",
    "        \"Flickr30k_manual\",\n",
    "        properties=[\n",
    "            Property(name=\"image\", data_type=DataType.BLOB),\n",
    "            Property(name=\"image_id\", data_type=DataType.TEXT),\n",
    "            Property(name=\"captions\", data_type=DataType.TEXT),\n",
    "        ],\n",
    "        vectorizer_config=[Configure.NamedVectors.none(name=\"image_vector\")]\n",
    "    )\n",
    "    print(\"Created Flickr30k_manual schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data_multi2vec(client, data_dir, batch_size=100):\n",
    "    \"\"\"Import data with multi2vec-clip\"\"\"\n",
    "    collection = client.collections.get(\"Flickr30k_multi2vec\")\n",
    "    images_dir = os.path.join(data_dir, \"images\")\n",
    "    metadata_dir = os.path.join(data_dir, \"metadata\")\n",
    "    metadata_files = [f for f in os.listdir(metadata_dir) if f.endswith('.json')]\n",
    "    print(f\"Importing {len(metadata_files)} images for multi2vec\")\n",
    "\n",
    "    batch_errors = []\n",
    "    with collection.batch.fixed_size(batch_size=batch_size) as batch:\n",
    "        for metadata_file in tqdm(metadata_files):\n",
    "            try:\n",
    "                with open(os.path.join(metadata_dir, metadata_file), 'r') as f:\n",
    "                    metadata = json.load(f)\n",
    "                \n",
    "                image_path = os.path.join(images_dir, f\"image_{metadata['image_id']}.jpg\")\n",
    "                image_data, _ = read_image_data(image_path)\n",
    "                captions = process_metadata(metadata)\n",
    "                \n",
    "                batch.add_object(\n",
    "                    properties={\n",
    "                        \"image\": image_data,\n",
    "                        \"image_id\": metadata[\"image_id\"],\n",
    "                        \"captions\": captions\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                batch_errors.append(f\"Error processing {metadata_file}: {str(e)}\")\n",
    "                continue\n",
    "    if batch_errors:\n",
    "        print(f\"Encountered {len(batch_errors)} errors during batch import\")\n",
    "        for err in batch_errors[:5]:  # Print first 5 errors\n",
    "            print(err)\n",
    "    print(\"Finished multi2vec import\")\n",
    "\n",
    "def import_data_manual(client, data_dir, batch_size=100):\n",
    "    \"\"\"Import data with manual CLIP vectorization\"\"\"\n",
    "    collection = client.collections.get(\"Flickr30k_manual\")\n",
    "    images_dir = os.path.join(data_dir, \"images\")\n",
    "    metadata_dir = os.path.join(data_dir, \"metadata\")\n",
    "    metadata_files = [f for f in os.listdir(metadata_dir) if f.endswith('.json')]\n",
    "    print(f\"Importing {len(metadata_files)} images for manual\")\n",
    "\n",
    "    batch_errors = []\n",
    "    with collection.batch.fixed_size(batch_size=batch_size) as batch:\n",
    "        for metadata_file in tqdm(metadata_files):\n",
    "            try:\n",
    "                with open(os.path.join(metadata_dir, metadata_file), 'r') as f:\n",
    "                    metadata = json.load(f)\n",
    "                \n",
    "                image_path = os.path.join(images_dir, f\"image_{metadata['image_id']}.jpg\")\n",
    "                image_data, img = read_image_data(image_path)\n",
    "                captions = process_metadata(metadata)\n",
    "                \n",
    "                image_embedding = clip_model.encode(img, convert_to_numpy=True)\n",
    "                caption_list = metadata.get(\"captions\", [])\n",
    "                text_embedding = clip_model.encode(caption_list, convert_to_numpy=True).mean(axis=0) if caption_list else np.zeros_like(image_embedding)\n",
    "                combined_embedding = 0.7 * image_embedding + 0.3 * text_embedding\n",
    "                \n",
    "                batch.add_object(\n",
    "                    properties={\n",
    "                        \"image\": image_data,\n",
    "                        \"image_id\": metadata[\"image_id\"],\n",
    "                        \"captions\": captions\n",
    "                    },\n",
    "                    vector={\"image_vector\": combined_embedding.tolist()}\n",
    "                )\n",
    "                img.close() \n",
    "            except Exception as e:\n",
    "                batch_errors.append(f\"Error processing {metadata_file}: {str(e)}\")\n",
    "                continue\n",
    "    if batch_errors:\n",
    "        print(f\"Encountered {len(batch_errors)} errors during batch import\")\n",
    "        for err in batch_errors[:5]:\n",
    "            print(err)\n",
    "    print(\"Finished manual import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flickr30k_manual exists, skipping creation\n",
      "Flickr30k_multi2vec exists, skipping creation\n",
      "Importing 100 images for manual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished manual import\n",
      "Importing 100 images for multi2vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2012.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished multi2vec import\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    # Connect to Weaviate\n",
    "    client = weaviate.connect_to_local()\n",
    "\n",
    "    data_dir = \"flickr30k_sample\"\n",
    "    create_flickr_schema_manual(client)\n",
    "    create_flickr_schema_multi2vec(client)\n",
    "\n",
    "    import_data_manual(client, data_dir)\n",
    "    import_data_multi2vec(client, data_dir)\n",
    "\n",
    "    client.close ()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal_comparison",
   "language": "python",
   "name": "multimodal_comparison"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
